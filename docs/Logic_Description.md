# Agent Logic

The main agent logic is the following loop

* Select Action

1. Calculate a score bias
2. Calculate a score for each action/behavior
3. Select one action
4. Test if the action can be performed
5. Execute the action or execute Break instead

* Handle Interactions

* Update Happiness
* Update Attention

# Open Issues

* Happiness is too high and has no dynamic behavior
* The mechanics of desired and current action is not working, and so happiness is not decreased
* The motivation is not changing fast enough while executing an action see issue #94 [here](https://github.com/mapa17/breakfastclub/issues/94) 


# Action Selection

## Score Bias
The score bias is added to the current action, and substracted from the previous action
in order to prevent the agent from switching constantly between actions, and keep it onto the current action.

The function is an exponential falling decay, parameterized by the the conscientousness of
the agent. See a [plot here](https://www.wolframalpha.com/input/?i=plot+10.0+*+e**(-(1.0-0.3)*x)+from+x%3D0+to+5)

The intention is that over time (ticks) the bias is reduced, and that an agent with high conscientousness keeps a higher bias for a longer time. Therefore prolonging staying on the same task/action.

```C#
ACTION_SCORE_BIAS = 10.0

score_bias = (int)(ACTION_SCORE_BIAS * Math.Exp(-(1.0 - personality.conscientousness) * (float)ticksOnThisTask));
```

## Action Selection
Actions are selected on a probabilistic bases, giving actions with a higher score a higher chance to be selected - Similar to the score bias. This is done by squaring the scores before normalizing each score and calculating its corresponding probability,

<p align="center">
    <img src="/docs/images/score_squared.png" alt="Probability_calculation" width="400"/>
</p

## Handle Interactions
Interactive actions are **Chat** and **Quarrel**.
In both cases if an agent decides to execute that action, it selects randomly another agent in the classroom and sends a 'request' for that action.

The other agent will decide in its next turn if to accept or reject the request.

If the request is rejected the sending agent will try again fro two more times, before switching to another agent and will continue there.

The receiving agent is deciding to accept or reject the request depending on its personality and a random factor.
The receiving agent will generate a random number between [0, 1]
* for **Chat**: If that random number > agent.conscioentousness, accept the request, if not, reject
* for **Quarrel**: If that random number > receiving_agent.agreeableness, accept the request, if not, reject. 


## Update Happiness
At the moment Happiness should increase if the agent is performing its desired action, and decrease otherwise. Agents high on neuroticism should experience a stronger decline
in happiness.

**NOTE**: This is not working probably at the moment, because the whole topic of differentiating between desire and active action has to be redesigned.

```C#
HAPPINESS_INCREASE = 0.05;
HAPPINESS_DECREASE = 0.10;

if(currentAction == Desire)
{
    change = HAPPINESS_INCREASE;
}
else
{
    change = -HAPPINESS_DECREASE * (1.0 - personality.neuroticism);
}
happiness = AgentBehavior.boundValue(0.0, happiness + change, 1.0);
```

## Update Attention
The attention is a positive value in case the agent is studying.
If so, it is a value between [0, 1], that increases with consciousness and motivation, and reduced by noise in the classroom.

Noise is generated by each behavior (with quarrel generating the most, and study alone the least).

```C#
if((currentAction is StudyAlone) || (currentAction is StudyGroup))
{
    if (currentAction.state == AgentBehavior.ActionState.EXECUTING)
    {
        attention = AgentBehavior.boundValue(0.0, personality.conscientousness + motivation - classroom.noise, 1.0);
    }
} else {
    attention = 0.0;
}
```
# Behavior Score

Each Behavior/Action has a rate method that returns a score for that particular agent and behavior.

The rates are calculated based on two functions, following an exponential growth or decay, normalized
from y = [0, 1] between x = [0, 1].

They are plotted at

* [exp_decay(x)](https://www.wolframalpha.com/input/?i=plot+(exp((1-x)**2)-1)%2F(e-1)+from+x%3D0+to+1)
<p align="center">
    <img src="/docs/images/exp_decay.png" alt="Exp decay" width="400"/>
</p

* [exp_grow(x)](https://www.wolframalpha.com/input/?i=(exp(x**2)+-+1)++%2F+(exp(1)+-+1)for+x+%3D+0++to+1)
<p align="center">
    <img src="/docs/images/exp_growth.png" alt="Exp growth" width="400"/>
</p


In addition the score depends at least at one personality trait. The value calculated by the exponential function is added to that personality trait in a weighted sum.

All scores are cutoff between [0, 1].

## Chat
The score depends on extraversion and motivation, and it should be high if the agent is high on extraversion and low on motivation.


```C#
EXTRAVERSION_WEIGHT = 0.3;

extra = agent.personality.extraversion;
motivation_term = exp_decay(agent.motivation);

score = extra * EXTRAVERSION_WEIGHT + (motivation_term) * (1.0 - EXTRAVERSION_WEIGHT)
```

## Take a Break
Taking a break is equal to 'Chat' for introverts.

```C#
EXTRAVERSION_WEIGHT = 0.3;

extra = (1.0 - agent.personality.extraversion);
motivation_term = exp_decay(agent.motivation);

score = extra * EXTRAVERSION_WEIGHT + (motivation_term) * (1.0 - EXTRAVERSION_WEIGHT)
```

## Study Alone
This is the counterpart to taking a break. If the agent is motivated enough and an introvert
she should get a higher score.

```C#
EXTRAVERSION_WEIGHT = 0.5;

extra = (1.0 - agent.personality.extraversion);
motivation_term = exp_grow(agent.motivation);

score = extra * EXTRAVERSION_WEIGHT + (motivation_term) * (1.0 - EXTRAVERSION_WEIGHT)
```

## Study Group
The pervered way to study for extaverts. Should get a high score for motivated agents high on extraversion.

```C#
EXTRAVERSION_WEIGHT = 0.5;

extra = agent.personality.extraversion;
motivation_term = exp_grow(agent.motivation);

score = extra * EXTRAVERSION_WEIGHT + (motivation_term) * (1.0 - EXTRAVERSION_WEIGHT)
```

## Quarrel/Argue
This is the only behavior that has a slightly different formular, because it should
get a high score when the agent is unhappy and is motivated.

```C#
HAPPINESS_WEIGHT = 0.7;

motivation_term = exp_decay(agent.motivation)
happiness_term = exp_decay(agent.happiness)

score = (happiness_term * HAPPINESS_WEIGHT) + (motivation_term * (1.0 - HAPPINESS_WEIGHT));
```
